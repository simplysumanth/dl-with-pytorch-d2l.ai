{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl-ch5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6RC+WDNSaYYrY2GcaqZKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simplysumanth/dl-with-pytorch-d2l.ai/blob/main/dl_ch5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbTpjsrGE2Dd"
      },
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUUxAzXwF7Rb"
      },
      "source": [
        "net = nn.Sequential(\n",
        "    nn.Linear(20,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCMuAd6RGrwk",
        "outputId": "6fb91543-8e45-4adf-971f-e681a865ae7b"
      },
      "source": [
        "X = torch.rand(2,20)\n",
        "X.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szLsejKTG09G",
        "outputId": "2aeda244-6793-4a04-d655-5706da9ce246"
      },
      "source": [
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0682,  0.0058, -0.1413,  0.0624, -0.1441, -0.1405,  0.3156, -0.1748,\n",
              "         -0.0973, -0.2093],\n",
              "        [ 0.1116, -0.0235, -0.2719, -0.1638, -0.1499, -0.0076,  0.3217, -0.1536,\n",
              "         -0.1913, -0.1024]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YVgreoTG11-"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20,256)\n",
        "    self.out = nn.Linear(256,10)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.out(F.relu(self.hidden(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUZzmf4oK_Ak",
        "outputId": "fe57683c-5aee-4756-ac1a-79ed35ab2144"
      },
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0387,  0.0936,  0.1953, -0.1489, -0.0841, -0.0784, -0.1234,  0.0403,\n",
              "         -0.1476, -0.0161],\n",
              "        [ 0.1946,  0.1722,  0.0854, -0.0416, -0.0716,  0.0140, -0.2625,  0.0244,\n",
              "         -0.1652, -0.1082]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiGgo9pgi2aH"
      },
      "source": [
        "The same can be implemented in a modular way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxxpRoIyLNP2"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self,args):\n",
        "    super().__init__()\n",
        "    for i,module in enumerate(args):\n",
        "      self._modules[str(i)] = module\n",
        "  \n",
        "  def forward(self,X):\n",
        "    print('----------')\n",
        "    for blocks in self._modules.values():\n",
        "      print(blocks)\n",
        "      X = blocks(X)\n",
        "    print('------------')              \n",
        "    return X\n",
        "\n",
        "net = Network(nn.Sequential(\n",
        "    nn.Linear(20,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRN_k1FdjVsJ",
        "outputId": "27ea0974-d318-4ad8-f69f-21b8ad0679bb"
      },
      "source": [
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "Linear(in_features=20, out_features=256, bias=True)\n",
            "ReLU()\n",
            "Linear(in_features=256, out_features=10, bias=True)\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1256,  0.1404,  0.0114, -0.1972,  0.1033, -0.1459,  0.2155, -0.0606,\n",
              "         -0.0224, -0.0783],\n",
              "        [-0.1221,  0.2340,  0.0270, -0.1569,  0.0325, -0.1115,  0.3265,  0.0271,\n",
              "          0.1065, -0.0804]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlYVhj-ojuGs",
        "outputId": "16272799-306a-40ac-e983-5c5faafad1ac"
      },
      "source": [
        "#implement c*WT.X\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.rand_weight = torch.rand((20,20),requires_grad=False)\n",
        "    self.linear = nn.Linear(20,20)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.linear(x)\n",
        "    x = F.relu(torch.mm(x,self.rand_weight)+1)\n",
        "    x = self.linear(x)\n",
        "    while x.abs().sum() > 1:\n",
        "      x/=2\n",
        "    return x.sum()\n",
        "\n",
        "net = Network()\n",
        "net(X) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.2946, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mBhSUozrgdv"
      },
      "source": [
        "####QUIZ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNkcNYWhdHuA",
        "outputId": "f2ea9b65-683b-4877-cb27-3d6ad0a01bd0"
      },
      "source": [
        "#1.\n",
        "class MySequential(nn.Module):\n",
        "  def __init__(self,args):\n",
        "    super().__init__()\n",
        "    for i, module in enumerate(args):\n",
        "      self._modules[str(i)] = module\n",
        "\n",
        "  def forward(self,X):\n",
        "    for block in self._modules.values():\n",
        "      X = block(X)\n",
        "    return X\n",
        "\n",
        "net = MySequential(nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,2)))\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0128,  0.2135],\n",
              "        [-0.0061,  0.1850]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xKOa3Yisdqn",
        "outputId": "339ab9f5-dbc5-42d4-f31f-ea5426893325"
      },
      "source": [
        "#2. Take 2 blocks as an arguement -> return concatenated outputs of both \n",
        "class TwoBlocks(nn.Module):\n",
        "  def __init__(self,args1,args2):\n",
        "    super().__init__()\n",
        "    i = 0\n",
        "    for module in args1:\n",
        "      self._modules[str(i)] = module\n",
        "      i+=1\n",
        "    for module in args2:\n",
        "      self._modules[str(i)] = module\n",
        "      i+=1\n",
        "  \n",
        "  def forward(self,X):\n",
        "    for block in self._modules.values():\n",
        "      X = block(X)\n",
        "    return X\n",
        "\n",
        "net = TwoBlocks(nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,20)),nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,2)))\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0258,  0.1388],\n",
              "        [-0.0572,  0.1488]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0QitzZ3vXap",
        "outputId": "08be30f5-12bb-4285-e384-a0aa9b844916"
      },
      "source": [
        "#3. Implement factory function -> generates multiple instances of same block and build a larger network from it.\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20,256)\n",
        "    self.out = nn.Linear(256,20)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.out(F.relu(self.hidden(x)))\n",
        "\n",
        "class Factory(nn.Module):\n",
        "  def __init__(self, k):\n",
        "    super().__init__()\n",
        "    modules = []\n",
        "    for i in range(k):\n",
        "      modules.append(Network())\n",
        "    self.net = nn.Sequential(*modules)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "net = Factory(3)\n",
        "print(net.get_parameter)\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.get_parameter of Factory(\n",
            "  (net): Sequential(\n",
            "    (0): Network(\n",
            "      (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
            "      (out): Linear(in_features=256, out_features=20, bias=True)\n",
            "    )\n",
            "    (1): Network(\n",
            "      (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
            "      (out): Linear(in_features=256, out_features=20, bias=True)\n",
            "    )\n",
            "    (2): Network(\n",
            "      (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
            "      (out): Linear(in_features=256, out_features=20, bias=True)\n",
            "    )\n",
            "  )\n",
            ")>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1419, -0.1074,  0.0027,  0.0179,  0.0247,  0.0812,  0.0473, -0.0322,\n",
              "          0.0653,  0.0856,  0.0243,  0.0763, -0.0131, -0.0041, -0.0515, -0.0164,\n",
              "         -0.0075,  0.0581,  0.0924,  0.0167],\n",
              "        [-0.1439, -0.1074, -0.0049,  0.0215,  0.0308,  0.0832,  0.0518, -0.0380,\n",
              "          0.0618,  0.0879,  0.0202,  0.0698, -0.0149, -0.0048, -0.0578, -0.0232,\n",
              "         -0.0006,  0.0574,  0.0989,  0.0064]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znLdULdXzt6J"
      },
      "source": [
        "## Parameter Management"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4AaUjXC3t2K",
        "outputId": "99f81ed0-ce58-4fdd-d3e6-f720c32646d8"
      },
      "source": [
        "net = nn.Sequential(nn.Linear(4,8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size = (2,4))\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4379],\n",
              "        [-0.4572]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ruh0J0b4GDa",
        "outputId": "4d5e1ddb-8ae2-48a3-e870-850ecdf3a5a5"
      },
      "source": [
        "#Parameter Access\n",
        "print(net[2].state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.0067, -0.0484, -0.2627,  0.1842, -0.2240,  0.2429, -0.1095,  0.0324]])), ('bias', tensor([-0.3091]))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz6dz2vK4PTD",
        "outputId": "dc89bfdc-cd6f-42b4-bc73-a60788070091"
      },
      "source": [
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([-0.3091], requires_grad=True)\n",
            "tensor([-0.3091])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pOv2VnF73Lf",
        "outputId": "b287ba7c-a33c-4524-87a1-8267b75a57a1"
      },
      "source": [
        "list(net[0].named_parameters())[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('weight', Parameter containing:\n",
              " tensor([[ 0.4682,  0.3674, -0.1032, -0.4335],\n",
              "         [-0.0809, -0.2018,  0.1894, -0.4921],\n",
              "         [-0.4748,  0.3785, -0.2880, -0.0220],\n",
              "         [-0.0828, -0.3051,  0.3851,  0.1888],\n",
              "         [ 0.1979,  0.0236,  0.3052, -0.0218],\n",
              "         [-0.4078,  0.1224, -0.0224, -0.3762],\n",
              "         [ 0.2049,  0.0696, -0.2766,  0.3975],\n",
              "         [-0.4378,  0.4992,  0.2125,  0.0883]], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY-gr-NS8StQ",
        "outputId": "a73a8018-8fae-41cb-80be-2d6af2833dd3"
      },
      "source": [
        "print(*[(name,param) for name,param in net.named_parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0.weight', Parameter containing:\n",
            "tensor([[ 0.4682,  0.3674, -0.1032, -0.4335],\n",
            "        [-0.0809, -0.2018,  0.1894, -0.4921],\n",
            "        [-0.4748,  0.3785, -0.2880, -0.0220],\n",
            "        [-0.0828, -0.3051,  0.3851,  0.1888],\n",
            "        [ 0.1979,  0.0236,  0.3052, -0.0218],\n",
            "        [-0.4078,  0.1224, -0.0224, -0.3762],\n",
            "        [ 0.2049,  0.0696, -0.2766,  0.3975],\n",
            "        [-0.4378,  0.4992,  0.2125,  0.0883]], requires_grad=True)) ('0.bias', Parameter containing:\n",
            "tensor([ 0.0917,  0.3095, -0.1874,  0.2461,  0.3008, -0.3041,  0.0826, -0.1775],\n",
            "       requires_grad=True)) ('2.weight', Parameter containing:\n",
            "tensor([[ 0.0067, -0.0484, -0.2627,  0.1842, -0.2240,  0.2429, -0.1095,  0.0324]],\n",
            "       requires_grad=True)) ('2.bias', Parameter containing:\n",
            "tensor([-0.3091], requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7y8RjCsFqb8",
        "outputId": "510d39d4-e214-4d54-9751-4fabcd5efbca"
      },
      "source": [
        "#similarly\n",
        "net.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[ 0.4682,  0.3674, -0.1032, -0.4335],\n",
              "                      [-0.0809, -0.2018,  0.1894, -0.4921],\n",
              "                      [-0.4748,  0.3785, -0.2880, -0.0220],\n",
              "                      [-0.0828, -0.3051,  0.3851,  0.1888],\n",
              "                      [ 0.1979,  0.0236,  0.3052, -0.0218],\n",
              "                      [-0.4078,  0.1224, -0.0224, -0.3762],\n",
              "                      [ 0.2049,  0.0696, -0.2766,  0.3975],\n",
              "                      [-0.4378,  0.4992,  0.2125,  0.0883]])),\n",
              "             ('0.bias',\n",
              "              tensor([ 0.0917,  0.3095, -0.1874,  0.2461,  0.3008, -0.3041,  0.0826, -0.1775])),\n",
              "             ('2.weight',\n",
              "              tensor([[ 0.0067, -0.0484, -0.2627,  0.1842, -0.2240,  0.2429, -0.1095,  0.0324]])),\n",
              "             ('2.bias', tensor([-0.3091]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srhvokdpGJ74",
        "outputId": "a8624e10-aaad-4748-870c-3d5bb0afdc2b"
      },
      "source": [
        "## collecting  parameters from multiple blocks\n",
        "\n",
        "def block1():\n",
        "  return nn.Sequential(nn.Linear(4,8), nn.ReLU(), nn.Linear(8,4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "  net = nn.Sequential()\n",
        "  for i in range(4):\n",
        "    net.add_module(f'block {i}', block1())\n",
        "  return net\n",
        "\n",
        "net = nn.Sequential(block2(),nn.Linear(4,1))\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0519],\n",
              "        [0.0520]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-34CjEWHA2h",
        "outputId": "f9ce52cc-261a-4853-8a4c-46fad541b053"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA2vov00HCok"
      },
      "source": [
        "## Parameter Initilaization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTer2s3YDUUw",
        "outputId": "e1989b58-d1e9-4503-9541-f8bd60b40d89"
      },
      "source": [
        "def init_normal(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.normal_(m.weight, mean=0 , std=0.1)\n",
        "    nn.init.zeros_(m.bias)\n",
        "\n",
        "net.apply(init_normal)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (block 0): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 1): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 2): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 3): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0tTTYLgDp3h",
        "outputId": "741941d2-f785-43c9-a99c-b0c18b57c818"
      },
      "source": [
        "net[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (block 0): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 1): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 2): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (block 3): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB83tdApDsam"
      },
      "source": [
        "## Parameter Initiliazation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTxfK6CsMTsQ",
        "outputId": "ebf1a9a1-d8ce-4c80-f071-3e176c9df8b3"
      },
      "source": [
        "def init_normal(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.normal_(m.weight, mean=0, std=0.1)\n",
        "    nn.init.zeros_(m.bias)\n",
        "\n",
        "net.apply(init_normal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (block 0): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 1): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 2): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (block 3): Sequential(\n",
              "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ_PYqKKMqoC",
        "outputId": "238eed8e-7e19-488c-85d0-e27c2de70d84"
      },
      "source": [
        "print(*[(name,param) for name,param in net.named_parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0.block 0.0.weight', Parameter containing:\n",
            "tensor([[-0.0080, -0.0031,  0.1112, -0.0341],\n",
            "        [-0.1622,  0.0234,  0.0934, -0.1226],\n",
            "        [ 0.0324, -0.0134, -0.0507, -0.1373],\n",
            "        [-0.0781,  0.0732, -0.0221,  0.0852],\n",
            "        [ 0.0544,  0.0263, -0.1500, -0.0398],\n",
            "        [-0.0845, -0.0313,  0.1630, -0.0523],\n",
            "        [-0.0050,  0.1550, -0.0698, -0.0114],\n",
            "        [-0.0612,  0.0464,  0.0454,  0.0716]], requires_grad=True)) ('0.block 0.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 0.2.weight', Parameter containing:\n",
            "tensor([[-0.0200,  0.2373, -0.0473, -0.1253,  0.0606,  0.0312,  0.0175,  0.0974],\n",
            "        [ 0.1306,  0.0945, -0.0287,  0.0027,  0.0463,  0.0140,  0.0730,  0.0098],\n",
            "        [ 0.0924, -0.1254, -0.0833,  0.0379,  0.1290,  0.0413,  0.0792, -0.1536],\n",
            "        [ 0.1352, -0.1663,  0.1186, -0.0678,  0.1215,  0.1309, -0.0029,  0.1644]],\n",
            "       requires_grad=True)) ('0.block 0.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 1.0.weight', Parameter containing:\n",
            "tensor([[ 0.0300,  0.0522, -0.1003, -0.0783],\n",
            "        [-0.1273,  0.0666,  0.1166, -0.0089],\n",
            "        [ 0.0671, -0.0195, -0.0009, -0.1948],\n",
            "        [-0.0984, -0.0768, -0.0088, -0.1022],\n",
            "        [ 0.1222,  0.1154,  0.0669, -0.0319],\n",
            "        [-0.0349,  0.0863, -0.0615, -0.0444],\n",
            "        [ 0.0158, -0.1812, -0.1466,  0.1819],\n",
            "        [ 0.0506, -0.0670, -0.0320, -0.0636]], requires_grad=True)) ('0.block 1.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 1.2.weight', Parameter containing:\n",
            "tensor([[ 0.0339,  0.1785, -0.0137, -0.1294,  0.1194, -0.0430,  0.1980, -0.1343],\n",
            "        [-0.0265, -0.0018,  0.0018, -0.0251, -0.0536,  0.0786, -0.0588, -0.0584],\n",
            "        [-0.0524, -0.0967,  0.1092, -0.0743,  0.1714,  0.0528, -0.1785, -0.0117],\n",
            "        [-0.0100, -0.1449,  0.1569,  0.1350, -0.1992,  0.2222,  0.1443, -0.0217]],\n",
            "       requires_grad=True)) ('0.block 1.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 2.0.weight', Parameter containing:\n",
            "tensor([[-0.0122,  0.0252,  0.0429,  0.0432],\n",
            "        [ 0.0375, -0.0405, -0.0856,  0.0045],\n",
            "        [-0.0085, -0.0909, -0.0215,  0.1307],\n",
            "        [ 0.1432,  0.0288,  0.1372, -0.2042],\n",
            "        [ 0.0274,  0.1006,  0.0328,  0.1602],\n",
            "        [ 0.0268,  0.0953, -0.0599,  0.2766],\n",
            "        [ 0.0445, -0.2200, -0.1199, -0.0553],\n",
            "        [ 0.1285, -0.1202,  0.1039,  0.1256]], requires_grad=True)) ('0.block 2.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 2.2.weight', Parameter containing:\n",
            "tensor([[ 0.0350, -0.0588, -0.0723, -0.0966,  0.0862,  0.1047,  0.0145, -0.0240],\n",
            "        [-0.1956, -0.0103,  0.0057, -0.1883,  0.0134,  0.0952, -0.1292,  0.0536],\n",
            "        [-0.0138,  0.0153,  0.0097,  0.0610,  0.0088, -0.0672, -0.0148,  0.0104],\n",
            "        [ 0.0627,  0.0238, -0.0534, -0.0137, -0.0232, -0.0129,  0.0287, -0.1482]],\n",
            "       requires_grad=True)) ('0.block 2.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 3.0.weight', Parameter containing:\n",
            "tensor([[ 0.0493, -0.1522, -0.1051, -0.0414],\n",
            "        [ 0.1642,  0.0600,  0.0720, -0.0717],\n",
            "        [-0.1786, -0.0787,  0.1048,  0.0240],\n",
            "        [ 0.0030, -0.0330,  0.0434,  0.0215],\n",
            "        [-0.0931,  0.0479,  0.1217, -0.0153],\n",
            "        [-0.0181, -0.0859,  0.1217, -0.0080],\n",
            "        [-0.0032,  0.0046,  0.1133, -0.0025],\n",
            "        [-0.1543, -0.1025, -0.0342,  0.1690]], requires_grad=True)) ('0.block 3.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 3.2.weight', Parameter containing:\n",
            "tensor([[-0.2160, -0.1106, -0.0094,  0.2255,  0.0570, -0.0519, -0.0469, -0.0738],\n",
            "        [ 0.0397, -0.0048, -0.1132,  0.2669,  0.0254, -0.0401, -0.0104,  0.0572],\n",
            "        [-0.1570, -0.0714,  0.1404,  0.2684, -0.0383,  0.0063, -0.0479,  0.0070],\n",
            "        [ 0.0260,  0.0243,  0.1628,  0.1177, -0.0697,  0.1298, -0.0053,  0.0172]],\n",
            "       requires_grad=True)) ('0.block 3.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('1.weight', Parameter containing:\n",
            "tensor([[0.1295, 0.0278, 0.0581, 0.0388]], requires_grad=True)) ('1.bias', Parameter containing:\n",
            "tensor([0.], requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iICxZLicMtrm",
        "outputId": "50ff90a8-dc90-43c9-d172-4ba296a9293e"
      },
      "source": [
        "#lets init with constant for w and zeros for b\n",
        "def init_constant(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.constant_(m.weight,1)\n",
        "    nn.init.zeros_(m.bias)\n",
        "\n",
        "net.apply(init_constant)\n",
        "print(*[(name,param) for name, param in net.named_parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0.block 0.0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)) ('0.block 0.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 0.2.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)) ('0.block 0.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 1.0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)) ('0.block 1.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 1.2.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)) ('0.block 1.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 2.0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)) ('0.block 2.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 2.2.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)) ('0.block 2.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('0.block 3.0.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], requires_grad=True)) ('0.block 3.0.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)) ('0.block 3.2.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], requires_grad=True)) ('0.block 3.2.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0.], requires_grad=True)) ('1.weight', Parameter containing:\n",
            "tensor([[1., 1., 1., 1.]], requires_grad=True)) ('1.bias', Parameter containing:\n",
            "tensor([0.], requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGZXOSBXNfUX",
        "outputId": "4dcd3edd-9d69-44aa-abd7-09a65c653ec5"
      },
      "source": [
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2561960.2500],\n",
              "        [3132997.5000]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4D6vqFENx4M",
        "outputId": "f0c25fbf-e8b5-455f-e8ee-3120187b18ba"
      },
      "source": [
        "#We can apply diff init to diff blocks\n",
        "def xavier(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "def init_42(m):\n",
        "  if type(m) == nn.Linear:\n",
        "    nn.init.constant_(m.weight, 42)\n",
        "\n",
        "net[0][0].apply(xavier)\n",
        "net[0][1].apply(init_42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
              "  (3): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIzFilODNz7M"
      },
      "source": [
        "print(*[(name,param) for name, param in net.named_parameters()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLzzh6tXOwCP"
      },
      "source": [
        "#### **Tied Parameter**\n",
        "Sharing the parameter across multiple layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlhLdvpkRY-e",
        "outputId": "139f2c95-eb4b-4b3d-d75e-b189614f6608"
      },
      "source": [
        "shared = nn.Linear(8,8)\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(4,8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8,1)\n",
        ")\n",
        "net(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2128],\n",
              "        [0.2092]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXPrKUNjRy_P"
      },
      "source": [
        "##Quiz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIZWEE09SF3H",
        "outputId": "85a1e4b7-4845-4e28-835a-70e9be40c03b"
      },
      "source": [
        "#1. Implement a MLP and access its parameters\n",
        "import pprint\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(4,8)\n",
        "    self.fc2 = nn.Linear(8,8)\n",
        "    self.out = nn.Linear(8,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc2(F.relu(self.fc1(x))))\n",
        "    return self.out(x)\n",
        "\n",
        "p = pprint.PrettyPrinter(depth=6)\n",
        "\n",
        "net = MLP()\n",
        "print(net.get_parameter)\n",
        "p.pprint([(name, param) for name, param in net.named_parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.get_parameter of MLP(\n",
            "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
            ")>\n",
            "[('fc1.weight',\n",
            "  Parameter containing:\n",
            "tensor([[-0.1800, -0.0145,  0.0414, -0.0710],\n",
            "        [ 0.1744,  0.1987, -0.2241,  0.3152],\n",
            "        [-0.4376,  0.1019, -0.0557,  0.1810],\n",
            "        [ 0.4192, -0.3329,  0.2662, -0.1542],\n",
            "        [-0.0841,  0.3637, -0.0296, -0.1712],\n",
            "        [-0.3130,  0.1165, -0.2293, -0.2028],\n",
            "        [-0.2087,  0.2894,  0.4423,  0.0521],\n",
            "        [-0.0128, -0.0635, -0.2364,  0.4394]], requires_grad=True)),\n",
            " ('fc1.bias',\n",
            "  Parameter containing:\n",
            "tensor([-0.1795, -0.3467,  0.3317,  0.3666,  0.2337,  0.3701,  0.4180,  0.2220],\n",
            "       requires_grad=True)),\n",
            " ('fc2.weight',\n",
            "  Parameter containing:\n",
            "tensor([[ 0.0833,  0.1081,  0.2800,  0.3420, -0.1625,  0.2513,  0.0224,  0.0252],\n",
            "        [-0.2637,  0.0752,  0.0621, -0.3292, -0.2233, -0.1947,  0.1703,  0.0179],\n",
            "        [ 0.1942, -0.0040,  0.1499,  0.1188, -0.2372,  0.2584,  0.3499, -0.3267],\n",
            "        [ 0.2955, -0.0174,  0.0248, -0.3148, -0.0136, -0.0067, -0.1409, -0.2496],\n",
            "        [-0.0115,  0.1171, -0.1291,  0.1710,  0.3043,  0.2413,  0.3046, -0.2933],\n",
            "        [-0.2155,  0.1903,  0.0111, -0.2600, -0.3494,  0.2679,  0.2116, -0.1571],\n",
            "        [-0.0831, -0.0442, -0.1569, -0.2997, -0.0798, -0.1783, -0.2786, -0.3430],\n",
            "        [-0.1322,  0.0373,  0.0791, -0.2347,  0.3493, -0.2967,  0.1424, -0.2027]],\n",
            "       requires_grad=True)),\n",
            " ('fc2.bias',\n",
            "  Parameter containing:\n",
            "tensor([-0.1428,  0.3108,  0.2919,  0.1441,  0.1555,  0.3445,  0.0709,  0.2087],\n",
            "       requires_grad=True)),\n",
            " ('out.weight',\n",
            "  Parameter containing:\n",
            "tensor([[ 0.1907, -0.1298, -0.0195, -0.1747,  0.3509,  0.0686,  0.2334, -0.0187]],\n",
            "       requires_grad=True)),\n",
            " ('out.bias', Parameter containing:\n",
            "tensor([0.3097], requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M39kPV1bSyCo"
      },
      "source": [
        "## Custom Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lmcr4UGZLpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}